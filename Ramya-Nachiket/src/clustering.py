# -*- coding: utf-8 -*-
"""Clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tUg80K-anGy8Hi1bCvLafFCAvKbotpUQ
"""

!pip install "dask[complete]"

!pip install dask_jobqueue

import dask
import dask.dataframe as dd
from dask_jobqueue import SLURMCluster
from dask.distributed import Client
import numpy as np
import dask.array as da
import pandas as pd

graph = []
parent = dict()

# Creating a array to store parent of the node, part of disjoint-set operation.
 
def make_set(length):
    for i in range(0,length+1):
        parent[i] = i;

# Find Root of the tree in which node is part of - disjoint-set operation.

def find(node):
      
    while (parent.get(node) != node):
        x_parent = parent.get(parent.get(node))   
        node = x_parent
    
    return node 

# Combine two connected component 

def union(node_1,node_2):
    x = find(node_1)
    y = find(node_2)
    parent[x] = y

# Create Minimum - Spanning Tree using Kruskal's Algorithm with help of Disjoint-Set data-structure

def mstKruskal():
    
    minCost = 0
    mst = []
    for sublist in graph:
        x = sublist[0]
        y = sublist[1]
        cost = sublist[2]
        if (find(x) != find(y)):
            minCost += cost
            union(x, y)
            mst.append([x,y,cost])
            
    return (minCost,mst)

## Depth First Search -  USed to find the connectivity from a particular node
## Input - Graph, node (from which connectivity needs to be found)
## Output - List of Nodes connected from node  

def depth_first_search(clustergraph,node):
    stack = []
    visited = list(itertools.repeat(0,len(graph)))
    
    data = []
    stack.append(node)
    visited[node] = 1
    #print(node,visited[node])
    data.append(node)
    while len(stack) != 0:
        v = stack.pop()
        for sublist in clustergraph:
            x=sublist[0]
            y=sublist[1]
            if x == v:
                if visited[y] == 0:
                    stack.append(y)
                    visited[y] = 1
                    data.append(y)
            elif y == v:
                if visited[x] == 0:
                    stack.append(x)    
                    visited[x] = 1
                    data.append(x)
    return data

## Clustering using Minimum Spanning Tree
## Input  -  Minimum Spanning Tree and value (k) for number cluster
## Output -  Clusters of data.

def mstCluster(mst,k):
    cluster = 1
    globalclusterList = []
    clt_1 = []
    clt_2 = []
    mst.sort(key = lambda i:i[2] , reverse=True)
    
    for sublist in mst:
        if cluster < k:
            mst.remove(sublist) 
            u = sublist[0]
            v = sublist[1]
            clt_1=depth_first_search(mst,u)
            clt_2 =depth_first_search(mst,v) 
            #print(clt_1)
            #print(clt_2)
            
            for subcluster in globalclusterList:
                if subcluster[u] == True:
                    globalclusterList.remove(subcluster)
                elif subcluster[v] == True:
                    globalclusterList.remove(subcluster) 
            cluster+=1        
            globalclusterList.append(clt_1)
            globalclusterList.append(clt_2)
            
    return globalclusterList

# Calculate the Eucleadian Distance between two points of any dimension as dissimilarity measure 

def calcEucleadian(point_1,point_2): 
    sum_sq = np.sum(np.square(point_1 - point_2)) 
    return np.sqrt(sum_sq)

# Build a graph from data points present in CS file.

def buildGraph(filepath):
    
    
    #df= pd.read_csv(filepath)
    df = pd.read_excel(filepath)
    
    for i in range(0,(df.shape[0] - 1)):       
        for j in range(i+1,(df.shape[0])):
            if i!=j:
                    #j in chain(*graph) 
                point_1 = np.array(df.iloc[i,:])
                point_2 = np.array(df.iloc[j,:])
                weight= calcEucleadian(point_1,point_2)
                #toInsert = 1
                #for sublist in graph:
                #        if sublist == [j,i,weight]:
                #            toInsert = 0    
                graph.append(list((i,j,weight)))
                               
                #if toInsert == 1:
                
    return df.shape[0]

cluster = SLURMCluster(
    queue='generalsky',
    cores=24,
    memory="50 GB"
)
cluster.scale(jobs=10)

client = Client(cluster)

def main():
    
    csv_path = '/content/EM.xlsx'
    shp = buildGraph(csv_path)
    make_set(shp)
    #print(find(0))
    graph.sort(key = lambda i:i[2] , reverse=False)
    #print(graph)    
    
    dask.persist(graph)
    client.rebalance(graph)

    minCost,mst = dask.compute(mstKruskal())
    
    
    
    #print(depth_first_search(mst,2))
    #print(mstCluster(mst,2))
    #print(parent)
if __name__ == '__main__':
    main()